# 1️⃣ 为什么要做 Query 改写？

RAG 的召回依赖“用户问句 ↔ 文档索引空间”的语义对齐。真实场景中用户问句常常：

* 信息不完整（缺时间、实体、上下文）
* 表述随意（口语化、歧义、指代）
* 与文档域术语不匹配（专业词汇/缩写）
* 多跳/复合意图（一步问多个问题）

**Query 改写的目标**是：在不改变用户意图的前提下，生成更“可检索、可召回、可对齐”的查询表达，提高**召回率/准确率、减少幻觉、降低延迟成本**。

---

# 2️⃣ 方法谱系（从“轻”到“重”）

## A. 规范化与轻量规则（Preprocess / Canonicalization）

* **文本清洗**：大小写、标点、停用词、数字格式、时态/时间归一（“昨天”→绝对日期）。
* **实体标准化**：同义词、别名、缩写展开（“LLM”→“Large Language Model”）、度量单位统一。
* **领域词典映射**：将用户“俗称”替换为**索引中的专业名词**。
* **指代消解**（会话场景）：把“它/这个/上一个”替换成**上文的实体**与属性。

优点：便宜稳、零/低模型依赖。
缺点：覆盖有限，对复杂多跳帮助有限。
适用：日志类问答、FAQ、运营知识库、报表字段查询等。

---

## B. 基于检索反馈的改写（IR-driven, PRF/RM3/扩展词）

* **伪相关反馈（PRF）**：用原始查询先取 top-k 文档，从这些文档里抽关键词/短语，**回填/重写**查询（RM3/Rocchio）。
* **BM25 + KNN 混合扩展**：从候选文档中抽“实体/短语 + 语义近邻”构成改写候选。
* **词/短语共现图扩展**：利用共现统计或 PMI 添加高价值限定词（时间、地点、版本号等）。

优点：不依赖 LLM，稳定可控；适配**传统倒排**与**混合检索**。
缺点：首跳检索质量会影响扩展（“贫血查询”时容易漂移）。
适用：**结构相对稳定**的企业知识库、技术文档、法条政策检索。

---

## C. LLM 生成多样化等价查询（MultiQuery / Paraphrase）

* **多路同义改写**：让 LLM 产出 N 个等价提问（措辞、词序、语义角度多样化）。
* **去冗余与去近似**：对 N 个改写做嵌入去重（阈值/聚类），保留**多样性最大**的 m 个。
* **加权召回**：对每个改写独立检索，使用**MMR / Reciprocal Rank Fusion**做分数融合。

优点：显著提升召回覆盖，对**语义差异/口语化**鲁棒。
缺点：并发检索多次，**延迟与成本↑**，需要去重/融合。
适用：通用问答、开发者论坛/工单搜索、百科类检索。

---

## D. 任务分解式改写（Decomposition / Sub-queries）

* **多跳拆问**：把复合问题拆成子问题链（who/when/where/why/what），子问题分别检索再拼装。
* **Self-Ask / Plan-and-Solve**：让 LLM先产出“检索计划（子查询+依赖）”，逐步检索与填槽。
* **工具/结构感知**：若后端支持**结构化过滤**（时间段、作者、产品版本），则把约束显式写入子查询。

优点：对**多跳推理、信息聚合**效果突出，减少“全能大问题一次检索”的遗漏。
缺点：实现复杂、步骤多；规划质量决定上限。
适用：合规/政策比对、产品变更时间线、学术综述、竞争情报。

---

## E. HyDE：查询→虚拟文档→检索（Q2D）

* **Hypothetical Document Embeddings**：让 LLM根据问题生成一段“**假想文档**”，对该文档向量化后用于相似度检索。
* 变体：**Q2A2D**（先生成简答再扩成文档）、**Style-guided HyDE**（模仿库内写作风格）。

优点：当知识库文风/结构稳定（论文/技术 RFC/FAQ），**语义对齐强**。
缺点：有**内容漂移**风险；需要向量索引支持。
适用：技术规范、API 文档、学术/白皮书知识库。

---

## F. Step-back / Abstraction 改写（抽象化回溯）

* 让模型先把问题**上升一个层级**（更抽象/通用）的版本，检索**背景性**材料；
* 再用背景 + 原问句做**二次检索/回答**。

优点：缓解长尾专有名词/新概念冷启动；构建“先抬头看路”的背景。
缺点：两跳流程；抽象过度可能召回泛信息。
适用：新领域学习、概念解释、跨域对齐。

---

## G. Self-Querying（自注释检索）

* 让 LLM**显式产出检索过滤器**（如时间、地区、实体类型、来源可信级别），再把这些过滤与关键词/嵌入一起投递给**支持过滤的检索器**（如向量库 + 元数据过滤、ES/OpenSearch 过滤子句）。

优点：高可控、可审计、可落日志；便于**策略与合规**。
缺点：需要检索端支持结构化过滤；Prompt 设计要避免过拟合。
适用：企业内检索（合规、权限、产品线、版本/渠道等维度）。

---

## H. 跨语与术语对齐（Cross-lingual / Code-switch）

* **机器翻译 + 双语改写**：源语↔目标语双向生成，联合检索；
* **术语库/对照表**：把“中文问法→英文文档术语”或“俗称→标准名”。

优点：覆盖跨语料库、国际化团队。
缺点：翻译误差引入噪声；注意**固有名词**锁定。
适用：中英混检、开源生态、跨地区运营知识库。

---

# 3️⃣ 工程落地参考流程（可直接套）

```text
User Query
   │
   ├─ A. 轻量规范化（日期/实体/术语/指代）
   │
   ├─ B. 会话上下文融合（CQR：把“它/这个”补全）
   │
   ├─ C. 路由与选择器（根据问句类型/域选择策略）
   │     ├─ 单跳/事实类 → MultiQuery + 融合
   │     ├─ 多跳/时间线 → Decomposition + 结构过滤
   │     ├─ 文风一致库 → HyDE（Q→D）
   │     └─ 背景缺失 → Step-back + 二跳
   │
   ├─ D. 生成 N 个改写（含原始查询）
   │     └─ 嵌入去重（阈值/聚类），保留 m 个多样化候选
   │
   ├─ E. 并行检索（BM25 / 向量 / 混合），打分融合（RRF/MMR）
   │
   ├─ F. PRF 二次改写（可选，低延迟场景关闭）
   │
   └─ G. 重排（cross-encoder）→ 构造上下文窗口 → 生成回答
```

> **小技巧**
>
> 1. 任何生成式改写都保留**原始查询**作为一条候选；
> 2. 多路查询总数控制在 4–8 条；
> 3. 去重：余弦相似度 > 0.92 视为近义合并；
> 4. 融合优先用 **RRF**（简单强健），再加 MMR 去冗余。

---

# 4️⃣ Prompt 模板（即插即用）

**（1）会话改写 CQR）**

> 将用户当前问题改写为一个**自包含**的问题，补全上文省略的实体、时间、地点，并保持原意不变。输出：单行问题文本。
> 上下文摘要：{history\_brief}
> 当前问题：{q}

**（2）MultiQuery**

> 基于问题“{q}”，给出 **6** 种语义等价、措辞多样的检索查询。请避免重复和近义改写，尽量覆盖不同关键词组合与专业术语。仅以换行分隔，不要编号。

**（3）Decomposition（多跳拆问）**

> 将问题“{q}”拆成**最少**的若干检索子问题（每条可直接检索），并给出它们的依赖顺序（若有）。输出 JSON：\[{ "step":1, "sub\_query":"..." }, ...]。

**（4）HyDE（Q→D）**

> 针对问题“{q}”，撰写一段与企业文档风格一致的**假想摘要**（150–220字），使用专业术语与客观表述，不要编造具体数值与专有名词。仅输出正文。

**（5）Self-Querying（结构过滤）**

> 从问题“{q}”中抽取结构化过滤条件（时间范围/产品版本/地区/文档类型等）。输出 JSON：{"keywords":\[], "must\_filters":{}, "should\_filters":{}, "not\_filters":{}}。

---

# 5️⃣ 评估与监控（离线 & 在线）

**离线 IR 指标**

* Recall\@k / Precision\@k、nDCG\@k、MRR、Coverage（召回中包含答案文档的比例）
* 改写前后**命中率提升**与\*\*误召↑\*\*的权衡曲线
* 多路查询数量 vs 延迟/成本 曲线

**在线指标**

* 点击/停留/满意度、追问次数、人工审核通过率
* Answer Faithfulness（依据引用片段的一致性）
* 观测“查询漂移率”（改写后与原意偏离的比例）

**Ablation 方案**

* 逐层 ablate：去掉 HyDE / 去掉 Decomposition / 去掉 PRF…
* 控制变量：固定 Re-ranker 与生成模型，仅替换改写策略
* 不同域与任务分层看效果（FAQ/规范/政策/代码/票据）

---

# 6️⃣ 常见风险与治理

* **语义漂移**：加入**原查询保底**、语义差异阈值过滤、结构化约束白名单。
* **幻觉扩展词**：Prompt 明确“不引入未在问题中出现的专有名词与数字”；PRF 词只作为**should**而非 must。
* **延迟与成本**：多路查询数自适应（基于问题“不确定度/长度/实体缺失”）；缓存常见改写。
* **隐私与合规**：Self-Querying 输出的过滤器**可审计、可落库**；改写日志脱敏。
* **跨语噪声**：固有名词“保留原文”；术语表优先于通用翻译。

---

# 7️⃣ 参考实现骨架（伪代码）

```python
def rewrite_and_retrieve(q, ctx):
    # A. 轻量规范化
    q_norm = normalize(q, ctx)

    # B. 策略路由
    strategy = choose_strategy(q_norm, ctx)   # single, multiquery, decompose, hyde, stepback, selfquery

    # C. 生成候选查询
    queries = [q_norm]
    if strategy.multi_query:
        queries += llm_multiquery(q_norm, n=6)
    if strategy.decompose:
        subqs = llm_decompose(q_norm)
        queries += [s["sub_query"] for s in subqs]
    if strategy.hyde:
        pseudo_doc = llm_hyde(q_norm)
        return retrieve_by_embedding(pseudo_doc)  # Q→D→向量检索

    # D. 去重与裁剪
    queries = dedup_by_embedding(queries, thr=0.92, top_m=6)

    # E. 并行检索 + 融合
    pools = [retrieve_bm25(q) + retrieve_vector(q) for q in queries]
    merged = reciprocal_rank_fusion(pools, k=50)
    reranked = cross_encoder_rerank(q_norm, merged, top_k=8)

    return reranked
```

---

# 8️⃣ 场景化选型建议（速查表）

* **短问句/事实问答**：MultiQuery + RRF，保留原问句；必要时 PRF 二跳
* **多跳/时间线/依赖关系**：Decomposition + 结构过滤 + Rerank
* **规范/论文/白皮书**：HyDE（匹配文风）+ 向量检索 + 稳健重排
* **会话省略/指代多**：CQR + 轻量实体补全
* **跨语/术语差异**：双语改写 + 术语表 + 固有名词保留
* **强合规/可审计**：Self-Querying（显式过滤 JSON）+ 日志

---